{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import mlflow \n",
    "import mlflow.sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "df = pd.read_csv(r\"Bank_churn_modelling.csv\")\n",
    "x = df[['CreditScore', 'Geography', 'Gender', 'Age', 'Balance', 'NumOfProducts', 'IsActiveMember']]\n",
    "y =df['Exited']\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2,stratify=y,random_state=5)\n",
    "\n",
    "transformer = ColumnTransformer([('ohe',OneHotEncoder(drop=\"first\"),[1,2]),],remainder='passthrough')\n",
    "#transformer.fit(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'D:\\AI\\MLOps\\EYMAY23\\MLOps-with-Azure\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 290, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 383, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1096, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1089, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\utils\\file_utils.py\", line 215, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'D:\\AI\\MLOps\\EYMAY23\\MLOps-with-Azure\\mlruns\\1\\meta.yaml' does not exist.\n",
      "2023/05/09 09:16:00 INFO mlflow.tracking.fluent: Experiment with name 'W1D2' does not exist. Creating a new experiment.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'D:\\AI\\MLOps\\EYMAY23\\MLOps-with-Azure\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 290, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 383, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1096, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1089, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\utils\\file_utils.py\", line 215, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'D:\\AI\\MLOps\\EYMAY23\\MLOps-with-Azure\\mlruns\\1\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///d:/AI/MLOps/EYMAY23/MLOps-with-Azure/mlruns/292143052935320181', creation_time=1683603960438, experiment_id='292143052935320181', last_update_time=1683603960438, lifecycle_stage='active', name='W1D2', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"W1D2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldata = xtest\n",
    "evaldata['label'] = ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models import make_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/09 09:29:47 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\models\\signature.py:137: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/05/09 09:29:54 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/09 09:29:54 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "2023/05/09 09:29:56 WARNING mlflow.models.evaluation.default_evaluator: Skip logging model explainability insights because the shap explainer None requires all feature values to be numeric, and each feature column must only contain scalar values.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run():\n",
    "    model_pipeline = Pipeline([(\"transformer\",transformer),\n",
    "                                (\"model\",DecisionTreeClassifier(criterion='gini',min_samples_leaf=20,max_depth=8,\n",
    "                               class_weight='balanced',random_state=5))])\n",
    "    model_pipeline.fit(xtrain,ytrain)\n",
    "\n",
    "    def custom_metric_anshu(evaldata,_builtin_metric):\n",
    "        return 0.5\n",
    "    model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "    #model evaluation\n",
    "\n",
    "    result = mlflow.evaluate(model=model_uri,data=evaldata,\n",
    "    targets='label',model_type='classifier',\n",
    "    evaluators=['default'],\n",
    "    evaluator_config={\"default\":{\"metric_prefix\":\"test_\"}},\n",
    "    custom_metrics=[make_metric(eval_fn=custom_metric_anshu,greater_is_better=True)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///d:/AI/MLOps/EYMAY23/MLOps-with-Azure/mlruns/292143052935320181/e9ad5e069a3c4e538c05babdbd969c9b/artifacts/model'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/09 09:48:10 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\models\\signature.py:137: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run(run_name=\"Run1\"):\n",
    "    model_pipeline = Pipeline([(\"transformer\",transformer),\n",
    "                                (\"model\",DecisionTreeClassifier(criterion='gini',min_samples_leaf=20,max_depth=8,\n",
    "                               class_weight='balanced',random_state=5))])\n",
    "    model_pipeline.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature,ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/09 10:42:03 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\models\\signature.py:137: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/05/09 10:42:11 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/09 10:42:11 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "2023/05/09 10:42:13 WARNING mlflow.models.evaluation.default_evaluator: Skip logging model explainability insights because the shap explainer None requires all feature values to be numeric, and each feature column must only contain scalar values.\n",
      "C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlflow\\models\\signature.py:137: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      "  ['CreditScore': long, 'Geography': string, 'Gender': string, 'Age': long, 'Balance': double, 'NumOfProducts': long, 'IsActiveMember': long]\n",
      "outputs: \n",
      "  [Tensor('int64', (-1,))]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run():\n",
    "    model_pipeline = Pipeline([(\"transformer\",transformer),\n",
    "                                (\"model\",DecisionTreeClassifier(criterion='gini',min_samples_leaf=20,max_depth=8,\n",
    "                               class_weight='balanced',random_state=5))])\n",
    "    model_pipeline.fit(xtrain,ytrain)\n",
    "\n",
    "    def custom_metric_anshu(evaldata,_builtin_metric):\n",
    "        return 0.5\n",
    "    model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "    #model evaluation\n",
    "\n",
    "    result = mlflow.evaluate(model=model_uri,data=evaldata,\n",
    "    targets='label',model_type='classifier',\n",
    "    evaluators=['default'],\n",
    "    evaluator_config={\"default\":{\"metric_prefix\":\"test_\"}},\n",
    "    custom_metrics=[make_metric(eval_fn=custom_metric_anshu,greater_is_better=True)]\n",
    "    )\n",
    "\n",
    "    conda_env = {\"channels\":['conda-forge'],\n",
    "                \"dependencies\":['python=3.8.8','pip'],\n",
    "                \"name\":'mlflow-env'}\n",
    "\n",
    "    # infer signature automatically\n",
    "    signature1 = infer_signature(xtrain,model_pipeline.predict(xtrain))\n",
    "    print(signature1)\n",
    "\n",
    "    # specify signature manually\n",
    "    input_schema = Schema([\n",
    "        ColSpec(\"double\",'CreditScore'),\n",
    "        ColSpec(\"string\",'Geography'),\n",
    "        ColSpec(\"string\",'Gender'),\n",
    "        ColSpec(\"double\",'Age'),\n",
    "        ColSpec(\"double\",'Balance'),\n",
    "        ColSpec(\"double\",'NumOfProducts'),\n",
    "        ColSpec(\"integer\",'IsActiveMember'),\n",
    "    ])\n",
    "    output_schema = Schema([ColSpec(\"integer\",'Exited'),])\n",
    "    signature2 = ModelSignature(inputs=input_schema,outputs=output_schema)\n",
    "\n",
    "    example = {\"CreditScore\":652.0,\"Geography\":'France',\"Gender\":\"Male\",\"Age\":45.0,\n",
    "                \"Balance\":152432.0,\"NumOfProducts\":2.0,\"IsActiveMember\":0}\n",
    "    mlflow.sklearn.log_model(model_pipeline,\"churn_model\",\n",
    "                                # conda_env = conda_env,\n",
    "                                signature = signature2,\n",
    "                                input_example=example\n",
    "                                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6a8a6f76dcf0482a877913af15707b21'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_run = mlflow.last_active_run()\n",
    "runid = last_run.info.run_id\n",
    "runid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_experiments(\"W2D1\")\n",
    "# runid = \"192e755fd3e5471eba2d0002f0155914\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'churn_prediction_name'.\n",
      "2023/05/09 11:38:25 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: churn_prediction_name, version 1\n",
      "Created version '1' of model 'churn_prediction_name'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1683612505617, current_stage='None', description=None, last_updated_timestamp=1683612505617, name='churn_prediction_name', run_id='6a8a6f76dcf0482a877913af15707b21', run_link=None, source='file:///d:/AI/MLOps/EYMAY23/MLOps-with-Azure/mlruns/292143052935320181/6a8a6f76dcf0482a877913af15707b21/artifacts/churn_model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model registration\n",
    "model_uri = f\"runs:/{runid}/churn_model\"\n",
    "model_reg_name = \"churn_prediction_name\"\n",
    "mlflow.register_model(model_uri,model_reg_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

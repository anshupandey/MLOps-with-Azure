{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Models\n",
    "\n",
    "You can use Azure Machine Learning to interpret a model by using an *explainer* that quantifies the amount of influence each feature contribues to the predicted label. There are many common explainers, each suitable for different kinds of modeling algorithm; but the basic approach to using them is the same.\n",
    "\n",
    "## Install SDK packages\n",
    "\n",
    "Let's start by ensuring that you have the latest version of the Azure ML SDK installed, including the *explain* optional package. In addition, you'll install the Azure ML Interpretability library. You can use this to interpret many typical kinds of model, even if they haven't been trained in an Azure ML experiment or registered in an Azure ML workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azureml-sdk[explain,notebooks]\n",
      "  Downloading azureml_sdk-1.50.0-py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: azureml-core~=1.50.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-sdk[explain,notebooks]) (1.50.0)\n",
      "Collecting azureml-pipeline~=1.50.0\n",
      "  Downloading azureml_pipeline-1.50.0-py3-none-any.whl (2.4 kB)\n",
      "Collecting azureml-train-core~=1.50.0\n",
      "  Downloading azureml_train_core-1.50.0-py3-none-any.whl (8.6 MB)\n",
      "     ---------------------------------------- 8.6/8.6 MB 226.2 kB/s eta 0:00:00\n",
      "Collecting azureml-train-automl-client~=1.50.0\n",
      "  Downloading azureml_train_automl_client-1.50.0-py3-none-any.whl (136 kB)\n",
      "     ------------------------------------ 136.2/136.2 kB 191.9 kB/s eta 0:00:00\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.50.0\n",
      "  Downloading azureml_dataset_runtime-1.50.0-py3-none-any.whl (2.3 kB)\n",
      "Collecting azureml-explain-model~=1.50.0\n",
      "  Downloading azureml_explain_model-1.50.0-py3-none-any.whl (20 kB)\n",
      "Collecting azureml-contrib-notebook~=1.50.0\n",
      "  Downloading azureml_contrib_notebook-1.50.0-py3-none-any.whl (28 kB)\n",
      "Collecting azureml-widgets~=1.50.0\n",
      "  Downloading azureml_widgets-1.50.0-py3-none-any.whl (14.1 MB)\n",
      "     -------------------------------------- 14.1/14.1 MB 104.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: ipykernel in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-contrib-notebook~=1.50.0->azureml-sdk[explain,notebooks]) (6.19.2)\n",
      "Requirement already satisfied: nbconvert<8 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-contrib-notebook~=1.50.0->azureml-sdk[explain,notebooks]) (6.5.4)\n",
      "Requirement already satisfied: ipython in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-contrib-notebook~=1.50.0->azureml-sdk[explain,notebooks]) (8.10.0)\n",
      "Collecting azureml-pipeline-core~=1.50.0\n",
      "  Downloading azureml_pipeline_core-1.50.0.post1-py3-none-any.whl (312 kB)\n",
      "     ------------------------------------ 312.9/312.9 kB 220.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: jupyter-client<8 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-contrib-notebook~=1.50.0->azureml-sdk[explain,notebooks]) (7.3.4)\n",
      "Collecting papermill<3\n",
      "  Downloading papermill-2.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pytz in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (2022.7)\n",
      "Requirement already satisfied: backports.tempfile in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (1.0)\n",
      "Requirement already satisfied: jmespath<2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (0.10.0)\n",
      "Requirement already satisfied: pkginfo in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (1.9.6)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.15.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (1.22.0)\n",
      "Requirement already satisfied: jsonpickle<4.0.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (3.0.1)\n",
      "Requirement already satisfied: packaging<=23.0,>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (22.0)\n",
      "Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (1.1.28)\n",
      "Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (0.61.1)\n",
      "Requirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (39.0.1)\n",
      "Requirement already satisfied: docker<7.0.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (6.1.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (1.26.14)\n",
      "Requirement already satisfied: azure-mgmt-authorization<4,>=0.40.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (3.0.0)\n",
      "Requirement already satisfied: msrestazure<=0.6.4,>=0.4.33 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (0.6.4)\n",
      "Requirement already satisfied: azure-mgmt-storage<=21.0.0,>=16.0.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (21.0.0)\n",
      "Requirement already satisfied: humanfriendly<11.0,>=4.7 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (10.0)\n",
      "Requirement already satisfied: pathspec<1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (0.10.3)\n",
      "Requirement already satisfied: azure-mgmt-resource<=22.0.0,>=15.0.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (22.0.0)\n",
      "Requirement already satisfied: requests[socks]<3.0.0,>=2.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (2.28.1)\n",
      "Requirement already satisfied: paramiko<4.0.0,>=2.0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (2.8.1)\n",
      "Requirement already satisfied: azure-mgmt-containerregistry<11,>=8.2.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (10.1.0)\n",
      "Requirement already satisfied: SecretStorage<4.0.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (3.3.3)\n",
      "Requirement already satisfied: ndg-httpsclient<=0.5.1 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (0.5.1)\n",
      "Requirement already satisfied: PyJWT<3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (2.4.0)\n",
      "Requirement already satisfied: adal<=1.2.7,>=1.2.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (1.2.7)\n",
      "Requirement already satisfied: knack~=0.10.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (0.10.1)\n",
      "Requirement already satisfied: msal-extensions<=1.0.0,>=0.3.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (1.0.0)\n",
      "Requirement already satisfied: msrest<=0.7.1,>=0.5.1 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (0.7.1)\n",
      "Requirement already satisfied: contextlib2<22.0.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (21.6.0)\n",
      "Requirement already satisfied: azure-core<2.0.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (1.26.4)\n",
      "Requirement already satisfied: pyopenssl<24.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (23.0.0)\n",
      "Requirement already satisfied: argcomplete<3 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (2.1.2)\n",
      "Requirement already satisfied: azure-mgmt-keyvault<11.0.0,>=0.40.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (10.2.1)\n",
      "Requirement already satisfied: numpy!=1.19.4,<1.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-dataset-runtime[fuse]~=1.50.0->azureml-sdk[explain,notebooks]) (1.23.5)\n",
      "Collecting pyarrow<=9.0.0,>=0.17.0\n",
      "  Downloading pyarrow-9.0.0-cp310-cp310-win_amd64.whl (19.5 MB)\n",
      "     -------------------------------------- 19.5/19.5 MB 108.5 kB/s eta 0:00:00\n",
      "Collecting azureml-dataprep<4.11.0a,>=4.10.0a\n",
      "  Downloading azureml_dataprep-4.10.7-py3-none-any.whl (38.2 MB)\n",
      "     -------------------------------------- 38.2/38.2 MB 136.8 kB/s eta 0:00:00\n",
      "Collecting fusepy<4.0.0,>=3.0.1\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting azureml-interpret~=1.50.0\n",
      "  Downloading azureml_interpret-1.50.0-py3-none-any.whl (52 kB)\n",
      "     ---------------------------------------- 52.1/52.1 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting azureml-pipeline-steps~=1.50.0\n",
      "  Downloading azureml_pipeline_steps-1.50.0-py3-none-any.whl (69 kB)\n",
      "     --------------------------------------- 69.5/69.5 kB 37.5 kB/s eta 0:00:00\n",
      "Collecting azureml-automl-core~=1.50.0\n",
      "  Downloading azureml_automl_core-1.50.0-py3-none-any.whl (245 kB)\n",
      "     ------------------------------------- 245.4/245.4 kB 88.5 kB/s eta 0:00:00\n",
      "Collecting azureml-telemetry~=1.50.0\n",
      "  Downloading azureml_telemetry-1.50.0-py3-none-any.whl (30 kB)\n",
      "Collecting azureml-train-restclients-hyperdrive~=1.50.0\n",
      "  Downloading azureml_train_restclients_hyperdrive-1.50.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: azure-storage-blob>=12.6.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-widgets~=1.50.0->azureml-sdk[explain,notebooks]) (12.16.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-widgets~=1.50.0->azureml-sdk[explain,notebooks]) (3.1.2)\n",
      "Requirement already satisfied: ipywidgets<8.0.0,>=7.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-widgets~=1.50.0->azureml-sdk[explain,notebooks]) (7.6.5)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azure-core<2.0.0->azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azure-core<2.0.0->azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (4.4.0)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azure-mgmt-authorization<4,>=0.40.0->azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (1.4.0)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azure-mgmt-keyvault<11.0.0,>=0.40.0->azureml-core~=1.50.0->azureml-sdk[explain,notebooks]) (0.6.1)\n",
      "Requirement already satisfied: jsonschema in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.50.0->azureml-sdk[explain,notebooks]) (4.17.3)\n",
      "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
      "  Downloading azureml_dataprep_native-38.0.0-cp310-cp310-win_amd64.whl (903 kB)\n",
      "     ------------------------------------ 903.7/903.7 kB 119.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.50.0->azureml-sdk[explain,notebooks]) (6.0)\n",
      "Requirement already satisfied: cloudpickle<3.0.0,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.50.0->azureml-sdk[explain,notebooks]) (2.0.0)\n",
      "Collecting dotnetcore2<4.0.0,>=3.0.0\n",
      "  Downloading dotnetcore2-3.1.23-py3-none-win_amd64.whl (31.7 MB)\n",
      "     ---------------------                   17.5/31.7 MB 19.8 kB/s eta 0:12:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 437, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 526, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\http\\client.py\", line 465, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\ssl.py\", line 1274, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\ssl.py\", line 1130, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 160, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 247, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 400, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 373, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 213, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 204, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 297, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 162, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 231, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 308, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 491, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 536, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 166, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 107, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 621, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 559, in read\n",
      "    with self._error_catcher():\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 442, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azureml-interpret\n",
      "  Using cached azureml_interpret-1.50.0-py3-none-any.whl (52 kB)\n",
      "Collecting shap<0.40.0\n",
      "  Downloading shap-0.39.0.tar.gz (356 kB)\n",
      "     ------------------------------------- 356.2/356.2 kB 68.5 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: azureml-core~=1.50.0 in c:\\users\\anshu\\appdata\\roaming\\python\\python310\\site-packages (from azureml-interpret) (1.50.0)\n",
      "Collecting numba<=0.55.2\n",
      "  Downloading numba-0.55.2-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 32.1 kB/s eta 0:00:00\n",
      "Collecting interpret-community==0.28.*\n",
      "  Downloading interpret_community-0.28.0-py3-none-any.whl (130 kB)\n",
      "     ------------------------------------- 130.5/130.5 kB 53.8 kB/s eta 0:00:00\n",
      "Collecting numpy<=1.22.3\n",
      "  Downloading numpy-1.22.3-cp310-cp310-win_amd64.whl (14.7 MB)\n",
      "     --------------------                     7.7/14.7 MB 35.9 kB/s eta 0:03:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 437, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 526, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\http\\client.py\", line 465, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\ssl.py\", line 1274, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\ssl.py\", line 1130, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 160, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 247, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 400, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 373, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 213, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 204, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 297, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 162, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 231, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 308, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 491, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 536, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 166, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 107, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 621, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 559, in read\n",
      "    with self._error_catcher():\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 442, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --user azureml-sdk[notebooks,explain]\n",
    "!pip install --upgrade --user azureml-interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (1.22.2)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.2-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.2\n",
      "    Uninstalling numpy-1.22.2:\n",
      "      Successfully uninstalled numpy-1.22.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\admin\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Temp\\\\pip-uninstall-uitvshl0\\\\libopenblas.el2c6ple4zyw3eceviv3oxxgrn2nrfm2.gfortran-win_amd64.dll'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --upgrade numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain a model\n",
    "\n",
    "Let's start with a model that is trained outside of Azure Machine Learning - Run the cell below to train a decision tree classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8923333333333333\n",
      "AUC: 0.8791059256679435\n",
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data = pd.read_csv('src/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "labels = ['not-diabetic', 'diabetic']\n",
    "X, y = data[features].values, data['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "\n",
    "print('Model trained.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process generated some model evaluation metrics based on a hold-back validation dataset, so you have an idea of how accurately it predicts; but how do the features in the data influence the prediction?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an explainer for the model\n",
    "\n",
    "Let's get a suitable explainer for the model from the Azure ML interpretability library you installed earlier. There are many kinds of explainer. In this example you'll use a *Tabular Explainer*, which is a \"black box\" explainer that can be used to explain many kinds of model by invoking an appropriate [SHAP](https://github.com/slundberg/shap) model explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C extension was not built during install!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabularExplainer ready!\n"
     ]
    }
   ],
   "source": [
    "from interpret.ext.blackbox import TabularExplainer\n",
    "\n",
    "# \"features\" and \"classes\" fields are optional\n",
    "tab_explainer = TabularExplainer(model,\n",
    "                             X_train, \n",
    "                             features=features, \n",
    "                             classes=labels)\n",
    "print(tab_explainer, \"ready!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get *global* feature importance\n",
    "\n",
    "The first thing to do is try to explain the model by evaluating the overall *feature importance* - in other words, quantifying the extent to which each feature influences the prediction based on the whole training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976e101f216e49e9b0236358040f782a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies : 0.22859005971817323\n",
      "BMI : 0.1845300849368329\n",
      "SerumInsulin : 0.12118250476190488\n",
      "Age : 0.12107678741496777\n",
      "PlasmaGlucose : 0.11261695330417862\n",
      "TricepsThickness : 0.04007569470359593\n",
      "DiastolicBloodPressure : 0.032914588386783176\n",
      "DiabetesPedigree : 0.025947302575315745\n"
     ]
    }
   ],
   "source": [
    "# you can use the training data or the test data here\n",
    "global_tab_explanation = tab_explainer.explain_global(X_train)\n",
    "\n",
    "# Get the top features by importance\n",
    "global_tab_feature_importance = global_tab_explanation.get_feature_importance_dict()\n",
    "for feature, importance in global_tab_feature_importance.items():\n",
    "    print(feature,\":\", importance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature importance is ranked, with the most important feature listed first.\n",
    "\n",
    "### Get *local* feature importance\n",
    "\n",
    "So you have an overall view, but what about explaining individual observations? Let's generate *local* explanations for individual predictions, quantifying the extent to which each feature influenced the decision to predict each of the possible label values. In this case, it's a binary model, so there are two possible labels (non-diabetic and diabetic); and you can quantify the influence of each feature for each of these label values for individual observations in a dataset. You'll just evaluate the first two cases in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461544277fb741bab754542142d8877b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support for not-diabetic\n",
      "\tObservation 1\n",
      "\t\t BMI : 0.34551190476190474\n",
      "\t\t SerumInsulin : 0.326178571428571\n",
      "\t\t TricepsThickness : 0.14772619047619068\n",
      "\t\t Age : 0.0\n",
      "\t\t DiabetesPedigree : 0.0\n",
      "\t\t DiastolicBloodPressure : 0.0\n",
      "\t\t Pregnancies : 0.0\n",
      "\t\t PlasmaGlucose : -0.13984523809523786\n",
      "\t\t ----------\n",
      "\t\t Total: 0.6795714285714286 Prediction: not-diabetic\n",
      "\tObservation 2\n",
      "\t\t BMI : 0.49338095238095175\n",
      "\t\t Pregnancies : 0.4491738095238091\n",
      "\t\t DiastolicBloodPressure : 0.07351190476190483\n",
      "\t\t TricepsThickness : 0.00895000000000018\n",
      "\t\t DiabetesPedigree : -0.0020309523809522445\n",
      "\t\t Age : -0.09169285714285669\n",
      "\t\t PlasmaGlucose : -0.10446428571428557\n",
      "\t\t SerumInsulin : -0.14725714285714264\n",
      "\t\t ----------\n",
      "\t\t Total: 0.6795714285714288 Prediction: not-diabetic\n",
      "Support for diabetic\n",
      "\tObservation 1\n",
      "\t\t PlasmaGlucose : 0.13984523809523786\n",
      "\t\t Age : 0.0\n",
      "\t\t DiabetesPedigree : 0.0\n",
      "\t\t DiastolicBloodPressure : 0.0\n",
      "\t\t Pregnancies : 0.0\n",
      "\t\t TricepsThickness : -0.14772619047619068\n",
      "\t\t SerumInsulin : -0.326178571428571\n",
      "\t\t BMI : -0.34551190476190474\n",
      "\t\t ----------\n",
      "\t\t Total: -0.6795714285714285 Prediction: not-diabetic\n",
      "\tObservation 2\n",
      "\t\t SerumInsulin : 0.14725714285714264\n",
      "\t\t PlasmaGlucose : 0.10446428571428557\n",
      "\t\t Age : 0.0916928571428568\n",
      "\t\t DiabetesPedigree : 0.002030952380952189\n",
      "\t\t TricepsThickness : -0.008950000000000236\n",
      "\t\t DiastolicBloodPressure : -0.07351190476190472\n",
      "\t\t Pregnancies : -0.4491738095238091\n",
      "\t\t BMI : -0.49338095238095175\n",
      "\t\t ----------\n",
      "\t\t Total: -0.6795714285714286 Prediction: not-diabetic\n"
     ]
    }
   ],
   "source": [
    "# Get the observations we want to explain (the first two)\n",
    "X_explain = X_test[0:2]\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(X_explain)\n",
    "\n",
    "# Get local explanations\n",
    "local_tab_explanation = tab_explainer.explain_local(X_explain)\n",
    "\n",
    "# Get feature names and importance for each possible label\n",
    "local_tab_features = local_tab_explanation.get_ranked_local_names()\n",
    "local_tab_importance = local_tab_explanation.get_ranked_local_values()\n",
    "\n",
    "for l in range(len(local_tab_features)):\n",
    "    print('Support for', labels[l])\n",
    "    label = local_tab_features[l]\n",
    "    for o in range(len(label)):\n",
    "        print(\"\\tObservation\", o + 1)\n",
    "        feature_list = label[o]\n",
    "        total_support = 0\n",
    "        for f in range(len(feature_list)):\n",
    "            print(\"\\t\\t\", feature_list[f], ':', local_tab_importance[l][o][f])\n",
    "            total_support += local_tab_importance[l][o][f]\n",
    "        print(\"\\t\\t ----------\\n\\t\\t Total:\", total_support, \"Prediction:\", labels[predictions[o]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding explainability to a model training experiment\n",
    "\n",
    "As you've seen, you can generate explanations for models trained outside of Azure Machine Learning; but when you use experiments to train and register models in your Azure Machine Learning workspace, you can generate model explanations and log them.\n",
    "\n",
    "Run the code in the following cell to connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.49.0 to work with aml-ws2\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.get(name = \"aml-ws2\",\n",
    "                      subscription_id=\"84a5808b-5549-459a-98f2-f102e84fa1bb\",\n",
    "                      resource_group=\"EY23\")\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and explain a model using an experiment\n",
    "\n",
    "OK, let's create an experiment and put the files it needs in a local folder - in this case we'll just use the same CSV file of diabetes data to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'diabetes_train_and_explain\\\\diabetes.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_train_and_explain'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('diabetes.csv', os.path.join(experiment_folder, \"diabetes.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a training script that looks similar to any other Azure ML training script except that is includes the following features:\n",
    "\n",
    "- The same libraries to generate model explanations we used before are imported and used to generate a global explanation\n",
    "- The **ExplanationClient** library is used to upload the explanation to the experiment output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_train_and_explain/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Import Azure ML run library\n",
    "from azureml.core.run import Run\n",
    "\n",
    "# Import libraries for model explanation\n",
    "from azureml.interpret import ExplanationClient\n",
    "from interpret.ext.blackbox import TabularExplainer\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "labels = ['not-diabetic', 'diabetic']\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = data[features].values, data['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes.pkl')\n",
    "\n",
    "# Get explanation\n",
    "explainer = TabularExplainer(model, X_train, features=features, classes=labels)\n",
    "explanation = explainer.explain_global(X_test)\n",
    "\n",
    "# Get an Explanation Client and upload the explanation\n",
    "explain_client = ExplanationClient.from_run(run)\n",
    "explain_client.upload_model_explanation(explanation, comment='Tabular Explanation')\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run the experiment. Note that the **azureml-interpret** library is included in the training environment so the script can create a **TabularExplainer** and use the **ExplainerClient** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc695da0a9dc4089b49ce6484c93b38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "\"ServiceException:\\n\\tCode: 404\\n\\tMessage: (UserError) Workspace not found.\\n\\tDetails:\\n\\n\\tHeaders: {\\n\\t    \\\"Date\\\": \\\"Mon, 10 Apr 2023 10:30:02 GMT\\\",\\n\\t    \\\"Content-Type\\\": \\\"application/json\\\",\\n\\t    \\\"Transfer-Encoding\\\": \\\"chunked\\\",\\n\\t    \\\"Connection\\\": \\\"keep-alive\\\",\\n\\t    \\\"Vary\\\": \\\"Accept-Encoding\\\",\\n\\t    \\\"Request-Context\\\": \\\"appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d\\\",\\n\\t    \\\"x-ms-response-type\\\": \\\"error\\\",\\n\\t    \\\"Strict-Transport-Security\\\": \\\"max-age=15724800; includeSubDomains; preload\\\",\\n\\t    \\\"X-Content-Type-Options\\\": \\\"nosniff\\\",\\n\\t    \\\"x-aml-cluster\\\": \\\"vienna-westus-01\\\",\\n\\t    \\\"x-request-time\\\": \\\"0.056\\\",\\n\\t    \\\"Content-Encoding\\\": \\\"gzip\\\"\\n\\t}\\n\\tInnerException: {\\n    \\\"additional_properties\\\": {},\\n    \\\"error\\\": {\\n        \\\"additional_properties\\\": {\\n            \\\"debugInfo\\\": null\\n        },\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"severity\\\": null,\\n        \\\"message\\\": \\\"Workspace not found.\\\",\\n        \\\"message_format\\\": \\\"Workspace not found.\\\",\\n        \\\"message_parameters\\\": {},\\n        \\\"reference_code\\\": null,\\n        \\\"details_uri\\\": null,\\n        \\\"target\\\": null,\\n        \\\"details\\\": [],\\n        \\\"inner_error\\\": {\\n            \\\"additional_properties\\\": {},\\n            \\\"code\\\": \\\"NotFound\\\",\\n            \\\"inner_error\\\": {\\n                \\\"additional_properties\\\": {},\\n                \\\"code\\\": \\\"WorkspaceNotFound\\\",\\n                \\\"inner_error\\\": null\\n            }\\n        },\\n        \\\"additional_info\\\": null\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": \\\"cd6581398198dfaad524744f6e73cd80\\\",\\n        \\\"request\\\": \\\"83ae6b694bb39723\\\"\\n    },\\n    \\\"environment\\\": \\\"westus\\\",\\n    \\\"location\\\": \\\"westus\\\",\\n    \\\"time\\\": {},\\n    \\\"component_name\\\": \\\"run-history\\\"\\n}\""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes_train_and_explain_1681113677_c4dade97',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2023-04-10T08:18:37.131877Z',\n",
       " 'endTimeUtc': '2023-04-10T08:19:36.872193Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '84b164ea-0f64-49a2-b8c1-efc8bf2baa7b'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'explain-env',\n",
       "   'version': 'Autosave_2023-04-10T08:01:19Z_f987c458',\n",
       "   'assetId': 'azureml://locations/westus/workspaces/bd7e86b2-0039-418a-abf1-bd5cb5d7113c/environments/explain-env/versions/Autosave_2023-04-10T08:01:19Z_f987c458',\n",
       "   'autoRebuild': True,\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.8.13',\n",
       "      {'pip': ['azureml-defaults~=1.49.0', 'azureml-interpret~=1.49.0']},\n",
       "      'scikit-learn',\n",
       "      'pandas',\n",
       "      'pip'],\n",
       "     'name': 'project_environment'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230120.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://amlws2storage8a9e6eb546d.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes_train_and_explain_1681113677_c4dade97/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=pQYRPvkDuCXZKOtsUTnK7VXLfAulDtKkI%2FScQ1QVyLU%3D&skoid=bc177de7-8c2c-412a-a6e8-c69a8aaa307b&sktid=13a86542-2185-4187-8e07-7512f5525c55&skt=2023-04-10T06%3A23%3A48Z&ske=2023-04-11T14%3A33%3A48Z&sks=b&skv=2019-07-07&st=2023-04-10T08%3A09%3A44Z&se=2023-04-10T16%3A19%3A44Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://amlws2storage8a9e6eb546d.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes_train_and_explain_1681113677_c4dade97/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=dmq8i3LVMWbU5dRAyaQ8Aql0vxODYAsL8OlH6ddhZ18%3D&skoid=bc177de7-8c2c-412a-a6e8-c69a8aaa307b&sktid=13a86542-2185-4187-8e07-7512f5525c55&skt=2023-04-10T06%3A23%3A48Z&ske=2023-04-11T14%3A33%3A48Z&sks=b&skv=2019-07-07&st=2023-04-10T08%3A09%3A44Z&se=2023-04-10T16%3A19%3A44Z&sp=r',\n",
       "  'logs/azureml/5696_azureml.log': 'https://amlws2storage8a9e6eb546d.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes_train_and_explain_1681113677_c4dade97/logs/azureml/5696_azureml.log?sv=2019-07-07&sr=b&sig=Hc%2FDompT7mUSf3AnJ8xwqm%2FSfFpb9Etp2HyG67%2Fh1Tc%3D&skoid=bc177de7-8c2c-412a-a6e8-c69a8aaa307b&sktid=13a86542-2185-4187-8e07-7512f5525c55&skt=2023-04-10T06%3A23%3A48Z&ske=2023-04-11T14%3A33%3A48Z&sks=b&skv=2019-07-07&st=2023-04-10T08%3A09%3A12Z&se=2023-04-10T16%3A19%3A12Z&sp=r'},\n",
       " 'submittedBy': 'Anshu Pandey'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "explain_env = Environment(\"explain-env\")\n",
    "\n",
    "# Create a set of package dependencies (including the azureml-interpret package)\n",
    "packages = CondaDependencies.create(conda_packages=['scikit-learn','pandas','pip'],\n",
    "                                    pip_packages=['azureml-defaults','azureml-interpret'])\n",
    "explain_env.python.conda_dependencies = packages\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                      script='diabetes_training.py',\n",
    "                      environment=explain_env) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'diabetes_train_and_explain'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the feature importance values\n",
    "\n",
    "With the experiment run completed, you can use the **ExplanationClient** class to retrieve the feature importance from the explanation registered for the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature\tImportance\n",
      "Pregnancies \t 0.22241669017773605\n",
      "Age \t 0.10397090119692536\n",
      "BMI \t 0.09640834466086473\n",
      "SerumInsulin \t 0.06914593012498527\n",
      "PlasmaGlucose \t 0.049602730998427935\n",
      "TricepsThickness \t 0.022150138661136572\n",
      "DiastolicBloodPressure \t 0.018597062215891913\n",
      "DiabetesPedigree \t 0.01363786418670087\n"
     ]
    }
   ],
   "source": [
    "from azureml.interpret import ExplanationClient\n",
    "\n",
    "# Get the feature explanations\n",
    "client = ExplanationClient.from_run(run)\n",
    "engineered_explanations = client.download_model_explanation()\n",
    "feature_importances = engineered_explanations.get_feature_importance_dict()\n",
    "\n",
    "# Overall feature importance\n",
    "print('Feature\\tImportance')\n",
    "for key, value in feature_importances.items():\n",
    "    print(key, '\\t', value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the model explanation in Azure Machine Learning studio\n",
    "\n",
    "You can also click the **View run details** link in the Run Details widget to see the run in Azure Machine Learning studio, and view the **Explanations** tab. Then:\n",
    "\n",
    "1. Select the **Tabular Explanation** explainer.\n",
    "2. View the **Global Importance** chart, which shows the overall global feature importance.\n",
    "3. View the **Summary Importance** chart, which shows each data point from the test data in a *swarm*, *violin*, or *box* plot.\n",
    "4. Select an individual point to see the **Local Feature Importance** for the individual prediction for the selected data point.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More Information**: For more information about using explainers in Azure ML, see [the documentation](https://docs.microsoft.com/azure/machine-learning/how-to-machine-learning-interpretability). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
